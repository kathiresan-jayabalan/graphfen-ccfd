# artifacts

This folder is used to store **derived artifacts** generated by the GraphFEN-CCFD notebook during experiments.
These files are not meant to be committed to the repository (they should be ignored via `.gitignore`), but the
folder itself is kept so users know where to place or find outputs.

Typical contents include:

## 1. Model checkpoint (`.pth`)

A `.pth` file (for example, `bestgraphfenhetero.pth`) usually contains:

- The trained PyTorch modelâ€™s `state_dict` (all learnable parameters).
- Optionally, metadata such as epoch number, best validation metric, or optimizer state (depending on how you save it).

**Usage pattern:**

- **Saving** (inside the notebook):
  - When validation performance improves, the current model state is saved to `.pth`, so you can reload the best model later instead of the final training epoch.
- **Loading** (in a later session or deployment script):
  - You instantiate the same model architecture and then load the weights from the `.pth` file to reproduce results or run inference on new data.

Practical notes:

- `.pth` files can be large and are specific to the exact model architecture and library versions used.
- They should not be stored in version control for large-scale experiments; use this folder locally or with external storage (e.g., object store, model registry).

## 2. Serialized artifacts (`.pkl`)

A `.pkl` file (for example, `graphfenartifacts.pkl`) typically packages **non-model** objects that are needed to
reproduce preprocessing and evaluation. This may include:

- Feature scaler (e.g., `MinMaxScaler` or `StandardScaler`) used to normalize input features.
- ID mappings for heterogeneous graph construction (e.g., mappings for `card`, `merchant`, `device` indices).
- Feature names list, used to reconstruct column order for inference.
- Training history (loss, accuracy, precision, recall, F1, ROC-AUC, PR-AUC across epochs).
- Any additional configuration or metadata needed to reproduce the experiment.

**Usage pattern:**

- **Saving**:
  - At the end of the notebook run, the code serializes relevant Python objects into a single `.pkl` file so they can be reused without re-running preprocessing.
- **Loading**:
  - In a new notebook or script, you load this `.pkl` file to restore scalers, mappings, and metadata, ensuring that any new data is transformed and interpreted in exactly the same way as during training.

Practical notes:

- `.pkl` files are Python-specific and typically depend on library versions and object definitions.
- They should not be used as a long-term, language-agnostic interchange format, but are very useful for short- to medium-term experiment reproducibility.

## 3. Version control policy

- The **`artifacts/` folder contents** (other than this README) should be excluded in `.gitignore`.
- This pattern allows you to:
  - Keep the repository light and free of large binary files.
  - Avoid accidentally publishing sensitive model files or data-derived objects.
